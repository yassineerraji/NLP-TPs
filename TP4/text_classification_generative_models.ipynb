{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text classification with Generative Models\n",
        "Text\n",
        " classification is a common task in NLP, it involves categorizing text \n",
        "into predefined categories or classes based on its content. This task is\n",
        " essential in various applications, such as sentiment analysis, spam \n",
        "filtering, topic classification...\n",
        "\n",
        "![](Text%20classification%20with%20Generative%20Models%20-%20Computer%20Science%20Adventures_files/text-classification-huh.jpg)\n",
        "\n",
        "Now with all the generative models it's tempting to use them for \n",
        "classification tasks, but are they good at it? How can we measure the \n",
        "success of a classification model ? Let's find out ðŸ¤”\n",
        "\n",
        "For this example we will use the `rotten_tomatoes` dataset, it contains 50000 movie reviews with their corresponding sentiment (positive or negative)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/william/python-envs/data-science/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8530/8530 [00:00<00:00, 286221.59 examples/s]\n",
            "Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 565536.06 examples/s]\n",
            "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 516177.33 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the Rotten Tomatoes sentiment dataset\n",
        "data = load_dataset(\"rotten_tomatoes\")\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a task-specific model\n",
        "Using\n",
        " specific task models is the easiest way to solve our problem, we just \n",
        "need to find a model that fits our needs, download it and use it in a \n",
        "pipeline to test it on our data.\n",
        "\n",
        "> \n",
        "For this example we will use a `roberta` model to classify our data.\n",
        "\n",
        "We will use a `pipeline` object if you are not familiar with this read the [official doc](https://huggingface.co/docs/transformers/v4.24.0/main_classes/pipelines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "/Users/william/python-envs/data-science/lib/python3.14/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "\n",
        "def select_torch_device() -> torch.device:\n",
        "    \"\"\"Pick the best available device (CUDA > MPS > CPU).\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "device = select_torch_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load model into a pipeline\n",
        "# NOTE: `return_all_scores=True` is deprecated upstream but we keep it here\n",
        "# to preserve the exact output structure used later in the notebook.\n",
        "pipe = pipeline(\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    return_all_scores=True,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's run an inference loop to get the predictions for our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:29<00:00, 36.01it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset\n",
        "\n",
        "# Run inference on the test split.\n",
        "# This RoBERTa checkpoint outputs 3 labels (negative / neutral / positive).\n",
        "# We reproduce the original logic by only comparing negative vs positive scores.\n",
        "y_pred = []\n",
        "\n",
        "test_texts = KeyDataset(data[\"test\"], \"text\")\n",
        "for scores in tqdm(pipe(test_texts), total=len(data[\"test\"])):\n",
        "    negative_score = scores[0][\"score\"]\n",
        "    positive_score = scores[2][\"score\"]\n",
        "\n",
        "    # 0 -> negative, 1 -> positive\n",
        "    y_pred.append(int(np.argmax([negative_score, positive_score])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation\n",
        "Then\n",
        " we will define a function to evaluate how well the model performed by \n",
        "comparing predictions to actual labels. For this we will use the `classification_report` from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def evaluate_performance(y_true, y_pred) -> str:\n",
        "    \"\"\"Print (and return) a classification report for Rotten Tomatoes sentiment.\"\"\"\n",
        "    report = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"],\n",
        "    )\n",
        "    print(report)\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.76      0.88      0.81       533\n",
            "Positive Review       0.86      0.72      0.78       533\n",
            "\n",
            "       accuracy                           0.80      1066\n",
            "      macro avg       0.81      0.80      0.80      1066\n",
            "   weighted avg       0.81      0.80      0.80      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall the model is not bad he's correctly classifies 4 out of 5 reviews.\n",
        "\n",
        "> \n",
        "This is pretty good for sentiment analysis ðŸ¤Œ\n",
        "\n",
        "Here's a detailed analysis of this classification report:\n",
        "\n",
        "**ðŸ” Class-by-Class Analysis**\n",
        "\n",
        "Negative Review Performance\n",
        "\n",
        "- **Precision: 0.76** (76%)\n",
        "\n",
        "- When the model predicts \"negative\", it's correct 76% of the time\n",
        "\n",
        "- **24% false positives** - sometimes it incorrectly labels positive reviews as negative\n",
        "\n",
        "- **Recall: 0.88** (88%)\n",
        "\n",
        "- The model finds 88% of all actual negative reviews\n",
        "\n",
        "- **Only 12% false negatives** - rarely misses a negative review\n",
        "\n",
        "- **F1-score: 0.81** - Good balance, but recall is stronger than precision\n",
        "\n",
        "**Interpretation:** The model is **sensitive to negativity** - it catches almost all negative reviews but sometimes over-predicts negativity.\n",
        "\n",
        "Positive Review Performance\n",
        "\n",
        "- **Precision: 0.86** (86%)\n",
        "\n",
        "- When the model predicts \"positive\", it's correct 86% of the time\n",
        "\n",
        "- **14% false positives** - rarely mislabels negatives as positive\n",
        "\n",
        "- **Recall: 0.72** (72%)\n",
        "\n",
        "- The model only finds 72% of actual positive reviews\n",
        "\n",
        "- **28% false negatives** - misses over 1 in 4 positive reviews!\n",
        "\n",
        "- **F1-score: 0.78** - Slightly lower than negative class\n",
        "\n",
        "**Interpretation:** The model is **conservative with positivity** - when it says positive, it's usually right, but it misses many positive reviews (probably labeling them as negative instead).\n",
        "\n",
        "The Trade-off pattern we need to find\n",
        "\n",
        "There's an **inverse relationship** between the classes:\n",
        "\n",
        "- **Negative:** High recall (0.88), Lower precision (0.76) â†’ *Over-predicts negative*\n",
        "\n",
        "- **Positive:** High precision (0.86), Lower recall (0.72) â†’ *Under-predicts positive*\n",
        "\n",
        "This suggests the model has a **negative bias** - it's more likely to classify uncertain reviews as negative.\n",
        "\n",
        "**ðŸ“ˆ Aggregate Metrics**\n",
        "\n",
        "- **Macro avg (0.81, 0.80, 0.80)**: Simple average across both classes\n",
        "\n",
        "- **Weighted avg (0.81, 0.80, 0.80)**: Weighted by support (but since support is equal, same as macro)\n",
        "\n",
        "- **Support: 533 each** - Perfectly balanced dataset, so no class imbalance issues\n",
        "\n",
        "#### Conclusion\n",
        "**Strengths:**\n",
        "\n",
        "- âœ… 80% accuracy is solid\n",
        "\n",
        "- âœ… Excellent at detecting negative sentiment (88% recall)\n",
        "\n",
        "- âœ… When it predicts positive, it's usually right (86% precision)\n",
        "\n",
        "**Weaknesses:**\n",
        "\n",
        "- âš ï¸ Misses 28% of positive reviews\n",
        "\n",
        "- âš ï¸ Has a slight negative bias\n",
        "\n",
        "- âš ï¸ Could improve positive review detection\n",
        "\n",
        "ðŸ‘‰ If false negatives on positive reviews are costly (e.g., missing \n",
        "happy customers), you might want to adjust the classification threshold \n",
        "or retrain the model to be less pessimistic!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification tasks with embeddings\n",
        "Now let's see how we can use embeddings to classify our data.\n",
        "\n",
        "> \n",
        "What's aappening if we can not find a model that fits perfectly our needs ?\n",
        "\n",
        "Then we need to fine-tune a model to our specific task, but it will be long hard and costly ... ðŸ˜…\n",
        "\n",
        "> \n",
        "So what's the solution ?\n",
        "\n",
        "Use embeddings !\n",
        "\n",
        "### Supervised classification with embeddings\n",
        "Instead\n",
        " of using a pre-trained model for our specific task, we will use an \n",
        "embedding moidel for feature generation. Then those features will be \n",
        "used to train a classifier, this method is called **Supervised classification with embeddings** because we do not need to fine-tune the model, we just need to train a classifier on the features ðŸ§™\n",
        "\n",
        "For this example we will use a `sentence-transformers` model to generate embeddings for our data it's very popular and well-performing for this kind of task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:41<00:00,  6.51it/s]\n",
            "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.70it/s]\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Sentence-level embedding model (frozen) used to generate features\n",
        "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model = SentenceTransformer(embedding_model_name)\n",
        "\n",
        "# Convert text to embeddings (NumPy arrays)\n",
        "train_embeddings = model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
        "test_embeddings = model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.02250263 -0.07829173 -0.02303073 ... -0.00827931  0.02652684\n",
            "  -0.00201897]\n",
            " [ 0.04170237  0.0010974  -0.01553417 ... -0.02181629 -0.06359361\n",
            "  -0.00875287]]\n"
          ]
        }
      ],
      "source": [
        "# Quick sanity check: encode a couple of sentences\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8530, 768)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This shape shows that each of our 8530 input documents has an embeddings dimension of 768 !\n",
        "\n",
        "Now let's train a very simple logisitic regression on our embeddings ðŸ¤“"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  display: none;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  overflow: visible;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".estimator-table summary {\n",
              "    padding: .5rem;\n",
              "    font-family: monospace;\n",
              "    cursor: pointer;\n",
              "}\n",
              "\n",
              ".estimator-table details[open] {\n",
              "    padding-left: 0.1rem;\n",
              "    padding-right: 0.1rem;\n",
              "    padding-bottom: 0.3rem;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table {\n",
              "    margin-left: auto !important;\n",
              "    margin-right: auto !important;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(odd) {\n",
              "    background-color: #fff;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:nth-child(even) {\n",
              "    background-color: #f6f6f6;\n",
              "}\n",
              "\n",
              ".estimator-table .parameters-table tr:hover {\n",
              "    background-color: #e0e0e0;\n",
              "}\n",
              "\n",
              ".estimator-table table td {\n",
              "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
              "}\n",
              "\n",
              ".user-set td {\n",
              "    color:rgb(255, 94, 0);\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td.value pre {\n",
              "    color:rgb(255, 94, 0) !important;\n",
              "    background-color: transparent !important;\n",
              "}\n",
              "\n",
              ".default td {\n",
              "    color: black;\n",
              "    text-align: left;\n",
              "}\n",
              "\n",
              ".user-set td i,\n",
              ".default td i {\n",
              "    color: black;\n",
              "}\n",
              "\n",
              ".copy-paste-icon {\n",
              "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
              "    background-repeat: no-repeat;\n",
              "    background-size: 14px 14px;\n",
              "    background-position: 0;\n",
              "    display: inline-block;\n",
              "    width: 14px;\n",
              "    height: 14px;\n",
              "    cursor: pointer;\n",
              "}\n",
              "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
              "        <div class=\"estimator-table\">\n",
              "            <details>\n",
              "                <summary>Parameters</summary>\n",
              "                <table class=\"parameters-table\">\n",
              "                  <tbody>\n",
              "                    \n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('penalty',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">penalty&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('dual',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">dual&nbsp;</td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('tol',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">tol&nbsp;</td>\n",
              "            <td class=\"value\">0.0001</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('C',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">C&nbsp;</td>\n",
              "            <td class=\"value\">1.0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('fit_intercept',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
              "            <td class=\"value\">True</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('intercept_scaling',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
              "            <td class=\"value\">1</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('class_weight',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">class_weight&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"user-set\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('random_state',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">random_state&nbsp;</td>\n",
              "            <td class=\"value\">42</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('solver',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">solver&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('max_iter',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">max_iter&nbsp;</td>\n",
              "            <td class=\"value\">100</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('multi_class',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">multi_class&nbsp;</td>\n",
              "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('verbose',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">verbose&nbsp;</td>\n",
              "            <td class=\"value\">0</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('warm_start',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">warm_start&nbsp;</td>\n",
              "            <td class=\"value\">False</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('n_jobs',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">n_jobs&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "\n",
              "        <tr class=\"default\">\n",
              "            <td><i class=\"copy-paste-icon\"\n",
              "                 onclick=\"copyToClipboard('l1_ratio',\n",
              "                          this.parentElement.nextElementSibling)\"\n",
              "            ></i></td>\n",
              "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
              "            <td class=\"value\">None</td>\n",
              "        </tr>\n",
              "    \n",
              "                  </tbody>\n",
              "                </table>\n",
              "            </details>\n",
              "        </div>\n",
              "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
              "    // Get the parameter prefix from the closest toggleable content\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
              "\n",
              "    const originalStyle = element.style;\n",
              "    const computedStyle = window.getComputedStyle(element);\n",
              "    const originalWidth = computedStyle.width;\n",
              "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
              "\n",
              "    navigator.clipboard.writeText(fullParamName)\n",
              "        .then(() => {\n",
              "            element.style.width = originalWidth;\n",
              "            element.style.color = 'green';\n",
              "            element.innerHTML = \"Copied!\";\n",
              "\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        })\n",
              "        .catch(err => {\n",
              "            console.error('Failed to copy:', err);\n",
              "            element.style.color = 'red';\n",
              "            element.innerHTML = \"Failed!\";\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        });\n",
              "    return false;\n",
              "}\n",
              "\n",
              "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
              "\n",
              "    element.setAttribute('title', fullParamName);\n",
              "});\n",
              "</script></body>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a lightweight classifier on top of frozen embeddings\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.85      0.86      0.85       533\n",
            "Positive Review       0.86      0.85      0.85       533\n",
            "\n",
            "       accuracy                           0.85      1066\n",
            "      macro avg       0.85      0.85      0.85      1066\n",
            "   weighted avg       0.85      0.85      0.85      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict previously unseen instances\n",
        "y_pred = clf.predict(test_embeddings)\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congrats with the embeddings training we acheive a better F1 score thant initially ðŸ¥³\n",
        "\n",
        "> \n",
        "This demonstrate the possibility of training a light classifier while keeping the embeddings model frozen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What if we do not have labeled data : unsupervised use case\n",
        "What\n",
        " would happen if we would not use a classifier at all? Instead, we can \n",
        "average the embeddings per class and apply cosine similarity to predict \n",
        "which classes match the documents best ðŸ§™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zero shot classification\n",
        "A\n",
        " zero shot classification is when a model can classify text into \n",
        "categories it has never been explicitly trained on, simply by \n",
        "understanding the semantic relationship between the input text and \n",
        "candidate label descriptions.\n",
        "\n",
        "In our case we do not have labeled data we will try to predict these \n",
        "labels of input text enven though the model was not trained on them ðŸ¥·\n",
        "\n",
        "> \n",
        "To perform zero-shot classification with embeddings, there is a \n",
        "little trick that we can use. We can describe our labels based on what \n",
        "they should represent. For example, a negative label for movie reviews \n",
        "can be described as \"This is a negative movie review.\" By describing and\n",
        " embedding the labels and documents, we have data that we can work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embeddings for our label descriptions\n",
        "label_texts = [\"A negative review\", \"A positive review\"]\n",
        "label_embeddings = model.encode(label_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To assign labels to documents, we can apply cosine similarity to the document label pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assign the label whose embedding is closest (cosine similarity)\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.78      0.77      0.78       533\n",
            "Positive Review       0.77      0.79      0.78       533\n",
            "\n",
            "       accuracy                           0.78      1066\n",
            "      macro avg       0.78      0.78      0.78      1066\n",
            "   weighted avg       0.78      0.78      0.78      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AN F1 score at 0.78 is quite impressive considering we did not used \n",
        "any labels !! This is thez perfect illustration why embeddings can be a \n",
        "very usefull tool !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text classification with generative models\n",
        "Generative\n",
        " language models like OpenAI's GPT differ fundamentally in their \n",
        "approach to classification compared to traditional methods.\n",
        "\n",
        "Rather than following conventional classification paradigms, these models function as sequence-to-sequence systems in short : **they receive text input and produce text output.**\n",
        "\n",
        "> \n",
        "While these generative models undergo training across diverse tasks, \n",
        "they typically cannot handle specialized use cases immediately. Consider\n",
        " feeding a movie review to such a model without additional guidance: the\n",
        " model would lack direction on how to process it.\n",
        "\n",
        "To achieve meaningful results, we must provide context and steer the \n",
        "model toward our desired outcomes. This guidance occurs primarily \n",
        "through carefully crafted instructions, known as prompts ðŸ˜Ž\n",
        "\n",
        "For our demo we will use the [groq API](https://github.com/groq/groq-python) because openAI do not give us a free API keys ðŸ˜…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /Users/william/python-envs/data-science/lib/python3.14/site-packages (0.37.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from groq) (2.12.5)\n",
            "Requirement already satisfied: sniffio in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->groq) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/william/python-envs/data-science/lib/python3.14/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the Groq Python client (needed only for the API demo below)\n",
        "! pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTANT:\n",
        "# - Put your API key in an environment variable named GROQ_API_KEY.\n",
        "# - In practice, set it in your shell / notebook environment or in a `.env` file.\n",
        "#\n",
        "# This command is a placeholder example (it may not persist across notebook cells\n",
        "# depending on your Jupyter environment):\n",
        "! export GROQ_API_KEY=\"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take one example review to test prompts quickly\n",
        "sample_text = data[\"test\"][\"text\"][0]\n",
        "print(f\"Review: {sample_text}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "\n",
        "# Load environment variables from a local `.env` file if present\n",
        "load_dotenv()\n",
        "\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# Simple prompt: force the model to answer with a single label\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a sentiment classifier. Respond with only 'positive' or 'negative'.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Classify the sentiment of this movie review: {sample_text}\",\n",
        "        },\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=10,\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "or we can output a scroe if you need more granularity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9\n"
          ]
        }
      ],
      "source": [
        "# Same idea, but return a numeric score in [0, 1] for finer granularity\n",
        "model_name = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You are a sentiment classifier. \"\n",
        "            \"Rate the sentiment as a number between 0 (negative) and 1 (positive). \"\n",
        "            \"Respond with only the number.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Rate the sentiment of this movie review: {sample_text}\",\n",
        "    },\n",
        "]\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=messages,\n",
        "    temperature=0,\n",
        "    max_tokens=10,\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's evaluate this classifier with the same classification repport and see how it's performing ðŸ¤”\n",
        "\n",
        "> \n",
        "Keep in mind this is a very simple prompt, if you need more control \n",
        "about the LLM output you can check how to structure the output of an LLM\n",
        " on the [openai doc](https://platform.openai.com/docs/guides/structured-outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def groq_generation(review_text: str, model: str = \"meta-llama/llama-4-scout-17b-16e-instruct\") -> str:\n",
        "    \"\"\"Return a sentiment score in [0, 1] from Groq (0=negative, 1=positive).\"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a sentiment classifier. \"\n",
        "                \"Rate the sentiment as a number between 0 (negative) and 1 (positive). \"\n",
        "                \"Respond with only the number.\"\n",
        "            ),\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Rate the sentiment of this movie review: {review_text}\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "        max_tokens=10,\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.8'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "groq_generation(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Optional) Run the scorer on the full test set (slow + costs API credits):\n",
        "# predictions = [groq_generation(doc) for doc in tqdm(data[\"test\"][\"text\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#y_pred = [int(pred) for pred in predictions]\n",
        "#evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Text2Text transfert transformers\n",
        "Let's explore a final technique called [text-to-text transfert transformers](https://arxiv.org/abs/1910.10683) or T5 models. ðŸ‘€ The architecture is similar to the original Transformers with ezncoder and decoder parts stacked together.\n",
        "\n",
        "> \n",
        "T5 reframes every common NLP tasks such as translation, summarization, classification, question answering. **As input text â†’ output text, simplifying model design and enabling multitask learning.**\n",
        "\n",
        "T5 was trained on the [Colossal Clean Crawled Corpus](https://github.com/allenai/c4-documentation), with a self-supervised objective called [span corruption](https://arxiv.org/abs/2401.13160), giving it strong generalization across NLP tasks.\n",
        "\n",
        "> \n",
        "Because T5 generates text tokens for answers and labels, it excels in\n",
        " zero-shot, few-shot, and instruction-based tasks, without needing \n",
        "task-specific heads or architectures ðŸ˜Ž"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Text-to-text classification with an instruction-tuned T5 model\n",
        "\n",
        "# Reuse our device helper from above\n",
        "device = select_torch_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-small\",\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8530/8530 [00:00<00:00, 58679.39 examples/s]\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 66658.64 examples/s]\n",
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 67463.27 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 't5'],\n",
              "        num_rows: 8530\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 't5'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 't5'],\n",
              "        num_rows: 1066\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare our data by turning classification into a text-to-text prompt\n",
        "prompt = \"Is the following sentence positive or negative? \"\n",
        "\n",
        "def add_t5_prompt(example):\n",
        "    return {\"t5\": prompt + example[\"text\"]}\n",
        "\n",
        "data = data.map(add_t5_prompt)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since this model generate text we need to map 0 for negative and 1 for positive then we can run our evaluation ðŸ¥¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:52<00:00, 20.24it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run inference\n",
        "# The model generates text; we map \"negative\" -> 0 and anything else -> 1.\n",
        "y_pred = []\n",
        "\n",
        "test_prompts = KeyDataset(data[\"test\"], \"t5\")\n",
        "for output in tqdm(pipe(test_prompts), total=len(data[\"test\"])):\n",
        "    generated = output[0][\"generated_text\"]\n",
        "    y_pred.append(0 if generated == \"negative\" else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Negative Review       0.83      0.85      0.84       533\n",
            "Positive Review       0.85      0.83      0.84       533\n",
            "\n",
            "       accuracy                           0.84      1066\n",
            "      macro avg       0.84      0.84      0.84      1066\n",
            "   weighted avg       0.84      0.84      0.84      1066\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GG for the Flan T5 model, 0.84 is a very good first F1 score ðŸ¥³\n",
        "\n",
        "## Conclusion\n",
        "Now\n",
        " I hope you have a better understanding of text classification and how \n",
        "to handle it with or without generative models. We know now that \n",
        "pretrained models are very good for classifying text !\n",
        "\n",
        "We also know that we can leverage the power of embeddings to use it \n",
        "as input to train classifiers. Now in the next episode we'll explore the\n",
        " world of text clustering and topic modeling ðŸ§™"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data-science",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
